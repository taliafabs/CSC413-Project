{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9e5e31436d754c43ad6bc34ddb9617cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_843f1379624d45958e9b1936a7cdb6bd",
              "IPY_MODEL_ec1d6944e27f4571a9de657b18438697"
            ],
            "layout": "IPY_MODEL_3714955f3f6946d4869405d26137c4dc"
          }
        },
        "843f1379624d45958e9b1936a7cdb6bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd9893bf8f654c49bceb93474549a0df",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_03b78c354b8e48bfa87c25099205f8d9",
            "value": "0.264 MB of 0.264 MB uploaded\r"
          }
        },
        "ec1d6944e27f4571a9de657b18438697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_107439f0da374544be084a11d99c9467",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fa0d3c11d9f441c973b7498c3ba7e14",
            "value": 1
          }
        },
        "3714955f3f6946d4869405d26137c4dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd9893bf8f654c49bceb93474549a0df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03b78c354b8e48bfa87c25099205f8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "107439f0da374544be084a11d99c9467": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fa0d3c11d9f441c973b7498c3ba7e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taliafabs/CSC413-Project/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introduction##\n",
        "This file contains the code that creates architecture and experiments its capabilities.\n",
        "\n",
        "The debugging print statements will show the matrix dimensions during computation.\n",
        "\n",
        "Running with GPU will significantly reduce the time consumption, it can also handle more data.\n",
        "\n",
        "Example. CPU (subset_ratio=0.1, batch_size <= 16), GPU (subset_ratio=10, batch_size=64)\n",
        "\n",
        "To run CapsNet alone, set hebb=False in the model declaration statement."
      ],
      "metadata": {
        "id": "n8Zz88FqU_8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CapsNet Architecture##\n",
        "The following section defines the CapsNet with Hebbian Softmax architecture, and tests whether it is functioning properly."
      ],
      "metadata": {
        "id": "XhVie1KvUncM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setting###"
      ],
      "metadata": {
        "id": "VTngO5BNIfoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "# !pip install wget\n",
        "import os\n",
        "# import wget\n",
        "from zipfile import ZipFile\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.autograd import Variable\n",
        "from collections import namedtuple, Counter, OrderedDict\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb"
      ],
      "metadata": {
        "id": "IzsFojVTIvNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "UXH4GNaJxdOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debugger\n",
        "debug = False\n",
        "def debug_message(msg):\n",
        "    if debug:\n",
        "        print(msg)\n",
        "\n",
        "# Save Activations for Hebbian Learning\n",
        "def save_activation(activations, name):\n",
        "    def hook(model, input, output):\n",
        "        activations[name] = output\n",
        "        debug_message(f\"Hook triggered for {name}, activation shape: {output.shape}\")\n",
        "    return hook\n",
        "\n",
        "def register_hooks(model, activations):\n",
        "    for name, layer in model.named_modules():\n",
        "        if name:\n",
        "            layer.register_forward_hook(save_activation(activations, name))"
      ],
      "metadata": {
        "id": "Zku44mKX0sUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network ###"
      ],
      "metadata": {
        "id": "qCh5qpuKI4YY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CapsuleNet(nn.Module):\n",
        "    def __init__(self, input_size, classes, routings, softmax=False):\n",
        "        super(CapsuleNet, self).__init__()\n",
        "        self.softmax = softmax\n",
        "        self.input_size = input_size\n",
        "        self.classes = classes\n",
        "        self.routings = routings\n",
        "\n",
        "        self.conv1 = nn.Conv2d(input_size[0], 256, kernel_size=9, stride=1, padding=0)\n",
        "        self.primarycaps = PrimaryCapsule(256, 256, 8, kernel_size=9, stride=2, padding=0)\n",
        "        self.digitcaps = DigitCapsule(in_num_caps=32 * 6 * 6, in_dim_caps=8,\n",
        "                                      out_num_caps=classes, out_dim_caps=16, routings=routings)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            OrderedDict([\n",
        "                (\"fc1\", nn.Linear(16 * classes, 512)),\n",
        "                (\"relu1\", nn.ReLU(inplace=True)),\n",
        "                (\"fc2\", nn.Linear(512, 1024)),\n",
        "                (\"relu2\", nn.ReLU(inplace=True)),\n",
        "                (\"fc3\", nn.Linear(1024, input_size[0] * input_size[1] * input_size[2])),\n",
        "                (\"sigmoid\", nn.Sigmoid())\n",
        "            ])\n",
        "        )\n",
        "\n",
        "        if softmax:\n",
        "            self.hebbsoftmax = HebbianSoftmax(input_size[0] * input_size[1] * input_size[2], classes)\n",
        "\n",
        "        self.to(DEVICE)\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        x = x.to(DEVICE)\n",
        "        debug_message(f\"Input shape: {x.shape}\")\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        debug_message(f\"Conv1 Output shape: {x.shape}\")\n",
        "\n",
        "        x = nn.functional.relu(x)\n",
        "        debug_message(f\"ReLU Ouput shape: {x.shape}\")\n",
        "\n",
        "        x = self.primarycaps(x)\n",
        "\n",
        "        x = self.digitcaps(x)\n",
        "\n",
        "        length = x.norm(dim=-1)\n",
        "        debug_message(f\"Length shape (class probabilities): {length.shape}\")\n",
        "\n",
        "        if y is None:  # during testing, no label is given, so we need to create one-hot coding using `length`\n",
        "            index = length.max(dim=1)[1]\n",
        "            y = torch.zeros(length.size(), device=DEVICE).scatter_(1, index.view(-1, 1), 1.)\n",
        "\n",
        "        y = y.to(DEVICE)\n",
        "        reconstruction = self.decoder((x * y[:, :, None]).view(x.size(0), -1))\n",
        "        debug_message(f\"Decoder Output shape: {reconstruction.shape}\")\n",
        "\n",
        "        if self.softmax:\n",
        "            length = self.hebbsoftmax(reconstruction)\n",
        "\n",
        "        return length, reconstruction.view(-1, *self.input_size)"
      ],
      "metadata": {
        "id": "WaqVhKLzI3ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layer ###"
      ],
      "metadata": {
        "id": "xo0oyw2cI68G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions\n",
        "def squash(inputs, axis=-1):\n",
        "    norm = torch.norm(inputs, p=2, dim=axis, keepdim=True)\n",
        "    scale = (norm**2 / (1 + norm**2)) / (norm + 1e-8)\n",
        "    return scale * inputs\n",
        "\n",
        "\n",
        "class PrimaryCapsule(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dim_caps, kernel_size, stride=1, padding=0):\n",
        "        super(PrimaryCapsule, self).__init__()\n",
        "        self.to(DEVICE)\n",
        "        self.dim_caps = dim_caps\n",
        "        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x.to(DEVICE)\n",
        "        debug_message(f\"PrimaryCapsule Input shape: {x.shape}\")\n",
        "\n",
        "        outputs = self.conv2d(x)\n",
        "        debug_message(f\"After Conv2D shape: {outputs.shape}\")\n",
        "\n",
        "        outputs = outputs.view(x.size(0), -1, self.dim_caps)\n",
        "        debug_message(f\"PrimaryCapsule Output shape: {outputs.shape}\")\n",
        "\n",
        "        return squash(outputs)\n",
        "\n",
        "\n",
        "class DigitCapsule(nn.Module):\n",
        "    def __init__(self, in_num_caps, in_dim_caps, out_num_caps, out_dim_caps, routings=3):\n",
        "        super(DigitCapsule, self).__init__()\n",
        "        self.to(DEVICE)\n",
        "        self.in_num_caps = in_num_caps\n",
        "        self.in_dim_caps = in_dim_caps\n",
        "        self.out_num_caps = out_num_caps\n",
        "        self.out_dim_caps = out_dim_caps\n",
        "        self.routings = routings\n",
        "        self.weight = nn.Parameter(0.01 * torch.randn(out_num_caps, in_num_caps, out_dim_caps, in_dim_caps))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x.to(DEVICE)\n",
        "        debug_message(f\"DigitCapsule Input shape: {x.shape}\")\n",
        "\n",
        "        x = x.view(x.size(0), 1, self.in_num_caps, self.in_dim_caps, 1)\n",
        "        debug_message(f\"After reshape for routing shape: {x.shape}\")\n",
        "\n",
        "        self.weight = self.weight.to(DEVICE)\n",
        "        x_hat = torch.squeeze(torch.matmul(self.weight, x), dim=-1)\n",
        "        debug_message(f\"x_hat shape: {x_hat.shape}\")\n",
        "\n",
        "        b = torch.zeros(x.size(0), self.out_num_caps, self.in_num_caps, device=DEVICE)\n",
        "        for i in range(self.routings):\n",
        "            c = F.softmax(b, dim=1)\n",
        "            debug_message(f\"Routing {i+1} coupling coefficients shape: {c.shape}\")\n",
        "            if i == self.routings - 1:\n",
        "                outputs = squash(torch.sum(c[:, :, :, None] * x_hat, dim=-2, keepdim=True))\n",
        "            else:\n",
        "                outputs = squash(torch.sum(c[:, :, :, None] * x_hat.detach(), dim=-2, keepdim=True))\n",
        "                b = b + torch.sum(outputs * x_hat.detach(), dim=-1)\n",
        "\n",
        "        debug_message(f\"DigitCapsule Output shape: {outputs.shape}\")\n",
        "        return torch.squeeze(outputs, dim=-2)\n",
        "\n",
        "\n",
        "class HebbianSoftmax(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(HebbianSoftmax, self).__init__()\n",
        "        self.to(DEVICE)\n",
        "        self.linear = nn.Linear(input_dim, output_dim, bias=False)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x.to(DEVICE)\n",
        "        debug_message(f\"HebbianSoftmax Input shape: {x.shape}\")\n",
        "        x = self.linear(x)\n",
        "        debug_message(f\"After Linear shape: {x.shape}\")\n",
        "        x = self.softmax(x)\n",
        "        debug_message(f\"HebbianSoftmax Output shape: {x.shape}\")\n",
        "        return x"
      ],
      "metadata": {
        "id": "YwtaMFBdI8uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train & Test ###"
      ],
      "metadata": {
        "id": "N7y1hhn_I9Je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions\n",
        "def init_hebb_param(class_labels, epochs):\n",
        "    Nmin = min(Counter(class_labels).values())\n",
        "    gamma = 1 / Nmin\n",
        "    T = Nmin * epochs  # should be epochs until convergence\n",
        "    return gamma, T\n",
        "\n",
        "\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_pred = y_pred.cpu().numpy()\n",
        "\n",
        "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "def show_reconstruction(x, x_recon):\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Original\")\n",
        "    plt.imshow(x[0].cpu().squeeze(), cmap='gray')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Reconstruction\")\n",
        "    plt.imshow(x_recon[0].cpu().detach().squeeze(), cmap='gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "D4GI_hM78xoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def caps_loss(y_true, y_pred, x, x_recon, lam_recon):\n",
        "    \"\"\"\n",
        "    Capsule loss = Margin loss + lam_recon * reconstruction loss.\n",
        "    \"\"\"\n",
        "    assert y_true.size() == y_pred.size(), f\"Shape mismatch: {y_true.size()} vs {y_pred.size()}\"\n",
        "    y_true = y_true.to(DEVICE)\n",
        "    y_pred = y_pred.to(DEVICE)\n",
        "    x = x.to(DEVICE)\n",
        "    x_recon = x_recon.to(DEVICE)\n",
        "\n",
        "    L = y_true * torch.clamp(0.9 - y_pred, min=0.) ** 2 + \\\n",
        "        0.5 * (1 - y_true) * torch.clamp(y_pred - 0.1, min=0.) ** 2\n",
        "    L_margin = L.sum(dim=1).mean()\n",
        "    L_recon = nn.MSELoss()(x_recon, x)\n",
        "    return L_margin + lam_recon * L_recon\n",
        "\n",
        "\n",
        "def test(model, test_loader, cfg):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    recon_mse = []\n",
        "    y_true_list = []\n",
        "    y_pred_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x = x.to(DEVICE)\n",
        "            y = y.to(DEVICE)\n",
        "            y = torch.zeros(y.size(0), cfg[\"classes\"], device=DEVICE).scatter_(1, y.view(-1, 1), 1.)  # change to one-hot coding\n",
        "            y_pred, x_recon = model(x)\n",
        "\n",
        "            # Loss\n",
        "            test_loss += caps_loss(y, y_pred, x, x_recon, cfg[\"lam_recon\"]).item() * x.size(0)\n",
        "\n",
        "            # Classification Accuracy\n",
        "            y_pred = y_pred.data.max(1)[1]\n",
        "            y_true = y.data.max(1)[1]\n",
        "            correct += y_pred.eq(y_true).cpu().sum().item()\n",
        "\n",
        "            # Reconstruction Accuracy\n",
        "            x_recon = 2 * x_recon - 1  # Transform to [-1, 1]\n",
        "            recon_error = torch.mean((x - x_recon) ** 2, dim=(1, 2, 3))\n",
        "            recon_mse.append(recon_error.mean().item())\n",
        "\n",
        "            # Metrics\n",
        "            y_true_list.append(y_true.cpu())\n",
        "            y_pred_list.append(y_pred.cpu())\n",
        "\n",
        "    data_size = len(test_loader.dataset)\n",
        "    test_loss /= data_size\n",
        "    test_acc = correct / data_size\n",
        "    test_recon_err = sum(recon_mse) / len(recon_mse)\n",
        "    precision, recall, f1 = compute_metrics(torch.cat(y_true_list), torch.cat(y_pred_list))\n",
        "    return test_loss, test_acc, test_recon_err, precision, recall, f1"
      ],
      "metadata": {
        "id": "oFqSvmAlCHab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, test_loader, cfg):\n",
        "    print('Training starts...')\n",
        "    writer = SummaryWriter(log_dir=cfg[\"save_dir\"])\n",
        "    wandb.init(\n",
        "        project=cfg[\"wb\"][\"project\"],\n",
        "        name=cfg[\"wb\"][\"run\"],\n",
        "        config={\n",
        "            \"learning_rate\": cfg[\"lr\"],\n",
        "            \"epochs\": cfg[\"epochs\"],\n",
        "            \"batch_size\": cfg[\"batch_size\"]\n",
        "            })\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr=cfg[\"lr\"])\n",
        "    lr_decay = lr_scheduler.ExponentialLR(optimizer, gamma=cfg[\"lr_decay\"])\n",
        "\n",
        "    all_labels = [label for _, labels in train_loader for label in labels]\n",
        "    gamma, T = init_hebb_param(all_labels, cfg[\"epochs\"])\n",
        "    class_occurrences = {i: 0 for i in range(cfg[\"classes\"])}\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    activations = {}\n",
        "    register_hooks(model, activations)\n",
        "\n",
        "    for epoch in range(cfg[\"epochs\"]):\n",
        "        debug_message(f\"Epoch: {epoch}\")\n",
        "        model.train()\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        train_loss = 0.0\n",
        "        correct = 0\n",
        "        recon_mse = []\n",
        "        y_true_list = []\n",
        "        y_pred_list = []\n",
        "\n",
        "        for _, (x, y) in enumerate(train_loader):\n",
        "            x = x.to(DEVICE)\n",
        "            y = y.to(DEVICE)\n",
        "            y = torch.zeros(y.size(0), cfg[\"classes\"], device=DEVICE).scatter_(1, y.view(-1, 1), 1.)  # change to one-hot coding\n",
        "            debug_message(f\"One-hot Encoding y: {y.shape}\")\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            y_pred, x_recon = model(x, y)\n",
        "            loss = caps_loss(y, y_pred, x, x_recon, cfg[\"lam_recon\"])\n",
        "            loss.backward()\n",
        "\n",
        "            for name, param in model.named_parameters():\n",
        "                debug_message(f\"Layer: {name}, Shape of theta: {param.shape}\")\n",
        "                if \"hebbsoftmax\" in name:\n",
        "                    with torch.no_grad():\n",
        "                        # intermediate SGD update\n",
        "                        intermediate_update = torch.zeros_like(param.data)\n",
        "                        h = activations[\"decoder\"]\n",
        "                        debug_message(f\"Layer: {name}, Shape of activation: {h.shape}\")\n",
        "                        error = y_pred - y\n",
        "                        debug_message(f\"Shape of error: {error.shape}\")\n",
        "                        grad = torch.matmul(error.T, h)\n",
        "                        debug_message(f\"Shape of gradient: {grad.shape}\")\n",
        "                        intermediate_update = param - lr * grad\n",
        "                        debug_message(f\"Shape of theta_0.5: {intermediate_update.shape}\")\n",
        "\n",
        "                        # Apply the blending mechanism\n",
        "                        n_t = y.sum(dim=0)  # occurrences of each class\n",
        "                        debug_message(f\"Shape of n_t: {n_t.shape}\")\n",
        "                        for i in range(cfg[\"classes\"]):\n",
        "                            n_t_i = n_t[i].item()\n",
        "                            if n_t_i > 0:\n",
        "                                lambda_t_i = max(1 / (class_occurrences[i] + 1), gamma) if class_occurrences[i] < T else 0\n",
        "                                h_bar_t_i = (h * y[:, i][:, None]).mean(dim=0)\n",
        "                                debug_message(f\"Shape of h_bar_t_i: {h_bar_t_i.shape}\")\n",
        "                                blended_update = lambda_t_i * h_bar_t_i + (1 - lambda_t_i) * intermediate_update[i]\n",
        "                                param.data[i].copy_(blended_update)\n",
        "                            else:\n",
        "                                param.data[i].copy_(intermediate_update[i])\n",
        "                            debug_message(f\"Shape of updated theta: {param.shape}\")\n",
        "                            class_occurrences[i] += n_t_i  # increment class occurrence counter\n",
        "\n",
        "            # Loss\n",
        "            train_loss += loss.item() * x.size(0)\n",
        "\n",
        "            # Classification Accuracy\n",
        "            y_pred = y_pred.data.max(1)[1]\n",
        "            y_true = y.data.max(1)[1]\n",
        "            correct += y_pred.eq(y_true).cpu().sum().item()\n",
        "\n",
        "            # Reconstruction Accuracy (MSE)\n",
        "            x_recon = 2 * x_recon - 1  # Transform to [-1, 1]\n",
        "            recon_error = torch.mean((x - x_recon) ** 2, dim=(1, 2, 3))\n",
        "            recon_mse.append(recon_error.mean().item())\n",
        "\n",
        "            # Metrics\n",
        "            y_true_list.append(y_true.cpu())\n",
        "            y_pred_list.append(y_pred.cpu())\n",
        "\n",
        "            optimizer.step()\n",
        "        lr_decay.step()\n",
        "\n",
        "        # Print All Metrics\n",
        "        data_size = len(train_loader.dataset)\n",
        "        train_loss /= data_size\n",
        "        train_acc = correct / data_size\n",
        "        train_recon_err = sum(recon_mse) / len(recon_mse)\n",
        "        precision, recall, f1 = compute_metrics(torch.cat(y_true_list), torch.cat(y_pred_list))\n",
        "\n",
        "        test_loss, test_acc, test_recon_acc, test_precision, test_recall, test_f1 = test(model, test_loader, cfg)\n",
        "\n",
        "        print('train: epoch = %d, loss = %.4f, classfication acc = %.4f, reconstruction err = %.4f' % (epoch, train_loss, train_acc, train_recon_err))\n",
        "        print('                   precision = %.4f, recall = %.4f, f1-score = %.4f' % (precision, recall, f1))\n",
        "        print('test: epoch = %d, loss = %.4f, classfication acc = %.4f, reconstruction err = %.4f' % (epoch, test_loss, test_acc, test_recon_acc))\n",
        "        print('                  precision = %.4f, recall = %.4f, f1-score = %.4f' % (test_precision, test_recall, test_f1))\n",
        "        wandb.log({\n",
        "              \"train_recon_err\": train_recon_err,\n",
        "              \"train_loss\": train_loss,\n",
        "              \"train_acc\": train_acc,\n",
        "              \"train_f1\": f1,\n",
        "              \"train_precision\": precision,\n",
        "              \"train_recall\": recall,\n",
        "              \"test_recon_err\": test_recon_acc,\n",
        "              \"test_loss\": test_loss,\n",
        "              \"test_acc\": test_acc,\n",
        "              \"test_f1\": test_f1,\n",
        "              \"test_precision\": test_precision,\n",
        "              \"test_recall\": test_recall,\n",
        "          })\n",
        "    print('Training Finished')\n",
        "    wandb.finish()\n",
        "    return model"
      ],
      "metadata": {
        "id": "cKkEIe8SB3sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_hebb(model, train_loader, test_loader, cfg):\n",
        "    print('Training starts...')\n",
        "    writer = SummaryWriter(log_dir=cfg[\"save_dir\"])\n",
        "    wandb.init(\n",
        "        project=cfg[\"wb\"][\"project\"],  # Replace with your project name\n",
        "        name=cfg[\"wb\"][\"run\"],             # Optional: Customize the run name\n",
        "        config={                     # Optional: Hyperparameters or config\n",
        "            \"learning_rate\": cfg[\"lr\"],\n",
        "            \"epochs\": cfg[\"epochs\"],\n",
        "            \"batch_size\": cfg[\"batch_size\"]\n",
        "                                     })\n",
        "    optimizer = Adam(model.parameters(), lr=cfg[\"lr\"])\n",
        "    lr_decay = lr_scheduler.ExponentialLR(optimizer, gamma=cfg[\"lr_decay\"])\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    activations = {}\n",
        "    register_hooks(model, activations)\n",
        "\n",
        "    for epoch in range(cfg[\"epochs\"]):\n",
        "        debug_message(f\"Epoch: {epoch}\")\n",
        "        model.train()\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        train_loss = 0.0\n",
        "        correct = 0\n",
        "        recon_mse = []\n",
        "        y_true_list = []\n",
        "        y_pred_list = []\n",
        "\n",
        "        for _, (x, y) in enumerate(train_loader):\n",
        "            x = x.to(DEVICE)\n",
        "            y = y.to(DEVICE)\n",
        "            y = torch.zeros(y.size(0), cfg[\"classes\"], device=DEVICE).scatter_(1, y.view(-1, 1), 1.)  # change to one-hot coding\n",
        "            debug_message(f\"One-hot Encoding y: {y.shape}\")\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            y_pred, x_recon = model(x, y)\n",
        "            loss = caps_loss(y, y_pred, x, x_recon, cfg[\"lam_recon\"])\n",
        "            loss.backward()\n",
        "\n",
        "            for name, param in model.named_parameters():\n",
        "                debug_message(f\"Layer: {name}, Shape of theta: {param.shape}\")\n",
        "                if \"decoder.fc2.weight\" in name or \"decoder.fc3.weight\" in name:\n",
        "                    h = activations[\"decoder.relu1\"] if \"decoder.fc2.weight\" in name else activations[\"decoder.relu2\"]\n",
        "                    debug_message(f\"Shape of h: {h.shape}\")\n",
        "                    error = activations[\"decoder.relu2\"] if \"decoder.fc2.weight\" in name else activations[\"decoder\"]\n",
        "                    debug_message(f\"Shape of error: {error.shape}\")\n",
        "                    with torch.no_grad():\n",
        "                        # intermediate SGD update\n",
        "                        intermediate_update = torch.zeros_like(param.data)\n",
        "                        grad = torch.matmul(error.T, h)\n",
        "                        debug_message(f\"Shape of gradient: {grad.shape}\")\n",
        "                        intermediate_update = param - lr * grad\n",
        "                        debug_message(f\"Shape of theta_0.5: {intermediate_update.shape}\")\n",
        "\n",
        "                        # Apply the blending mechanism\n",
        "                        lambda_t = 0.8\n",
        "                        h_bar_t = (h.unsqueeze(1) * error[:, :, None]).mean(dim=0)\n",
        "                        debug_message(f\"Shape of h_bar_t: {h_bar_t.shape}\")\n",
        "                        blended_update = lambda_t * h_bar_t + (1 - lambda_t) * intermediate_update\n",
        "                        param.data.copy_(blended_update)\n",
        "                        debug_message(f\"Shape of updated theta: {param.shape}\")\n",
        "\n",
        "            # Loss\n",
        "            train_loss += loss.item() * x.size(0)\n",
        "\n",
        "            # Classification Accuracy\n",
        "            y_pred = y_pred.data.max(1)[1]\n",
        "            y_true = y.data.max(1)[1]\n",
        "            correct += y_pred.eq(y_true).cpu().sum().item()\n",
        "\n",
        "            # Reconstruction Accuracy (MSE)\n",
        "            x_recon = 2 * x_recon - 1  # Transform to [-1, 1]\n",
        "            recon_error = torch.mean((x - x_recon) ** 2, dim=(1, 2, 3))\n",
        "            recon_mse.append(recon_error.mean().item())\n",
        "\n",
        "            # Metrics\n",
        "            y_true_list.append(y_true.cpu())\n",
        "            y_pred_list.append(y_pred.cpu())\n",
        "\n",
        "            optimizer.step()\n",
        "        lr_decay.step()\n",
        "\n",
        "        # Print All Metrics\n",
        "        data_size = len(train_loader.dataset)\n",
        "        train_loss /= data_size\n",
        "        train_acc = correct / data_size\n",
        "        train_recon_err = sum(recon_mse) / len(recon_mse)\n",
        "        precision, recall, f1 = compute_metrics(torch.cat(y_true_list), torch.cat(y_pred_list))\n",
        "\n",
        "        test_loss, test_acc, test_recon_acc, test_precision, test_recall, test_f1 = test(model, test_loader, cfg)\n",
        "\n",
        "        print('train: epoch = %d, loss = %.4f, classfication acc = %.4f, reconstruction err = %.4f' % (epoch, train_loss, train_acc, train_recon_err))\n",
        "        print('                   precision = %.4f, recall = %.4f, f1-score = %.4f' % (precision, recall, f1))\n",
        "        print('test: epoch = %d, loss = %.4f, classfication acc = %.4f, reconstruction err = %.4f' % (epoch, test_loss, test_acc, test_recon_acc))\n",
        "        print('                  precision = %.4f, recall = %.4f, f1-score = %.4f' % (test_precision, test_recall, test_f1))\n",
        "        wandb.log({\n",
        "              \"train_recon_err\": train_recon_err,\n",
        "              \"train_loss\": train_loss,\n",
        "              \"train_acc\": train_acc,\n",
        "              \"train_f1\": f1,\n",
        "              \"train_precision\": precision,\n",
        "              \"train_recall\": recall,\n",
        "\n",
        "              \"test_recon_err\": test_recon_acc,\n",
        "              \"test_loss\": test_loss,\n",
        "              \"test_acc\": test_acc,\n",
        "              \"test_f1\": test_f1,\n",
        "              \"test_precision\": test_precision,\n",
        "              \"test_recall\": test_recall,\n",
        "          })\n",
        "    print('Training Finished')\n",
        "    wandb.finish()\n",
        "    return model"
      ],
      "metadata": {
        "id": "9Qi0ycPv97jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline CNN Architecture ##\n",
        "The following section includes creates a baseline CNN to compare with CapsNet."
      ],
      "metadata": {
        "id": "PFIJtBrdkgb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNAutoencoder(nn.Module):\n",
        "    def __init__(self, input_size, classes, softmax=True):\n",
        "        super(CNNAutoencoder, self).__init__()\n",
        "        self.hebb = softmax\n",
        "        self.input_size = input_size\n",
        "        self.classes = classes\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 256, kernel_size=9, stride=1, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=9, stride=2, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 784, kernel_size=6, stride=1, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            OrderedDict([\n",
        "                (\"fc1\", nn.Linear(784, 512)),\n",
        "                (\"relu1\", nn.ReLU(inplace=True)),\n",
        "                (\"fc2\", nn.Linear(512, 1024)),\n",
        "                (\"relu2\", nn.ReLU(inplace=True)),\n",
        "                (\"fc3\", nn.Linear(1024, input_size[0] * input_size[1] * input_size[2])),\n",
        "                (\"sigmoid\", nn.Sigmoid())\n",
        "            ])\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(16 * classes, 128),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        if softmax:\n",
        "            debug_message(f\"Input size: {self.input_size}\")\n",
        "            self.hebbsoftmax = HebbianSoftmax(input_size[0]*input_size[1]*input_size[2], classes)\n",
        "        else: self.softmax = nn.Sequential(nn.Linear(input_size[0] * input_size[1] * input_size[2], 10),\n",
        "                                           nn.Softmax(dim=-1))\n",
        "\n",
        "        self.to(DEVICE)\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        x = x.to(DEVICE)\n",
        "        debug_message(f\"Input shape: {x.shape}\")\n",
        "\n",
        "        encoded = self.encoder(x)\n",
        "        debug_message(f\"Encoder Output shape: {encoded.shape}\")\n",
        "        if self.hebb:\n",
        "            classification = self.hebbsoftmax(encoded)\n",
        "        else:\n",
        "            classification = self.softmax(encoded)\n",
        "\n",
        "        reconstruction = self.decoder(encoded)\n",
        "        reconstruction = reconstruction.view(-1, *self.input_size)\n",
        "\n",
        "        debug_message(f\"Classifier Output shape: {classification.shape}\")\n",
        "        debug_message(f\"Decoder Output shape: {reconstruction.shape}\")\n",
        "        length = x.norm(dim=-1)\n",
        "\n",
        "        return classification, reconstruction"
      ],
      "metadata": {
        "id": "42Q_5VQSkvB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Experiments ##\n",
        "The following section includes all the experiments to investigate the model performance, complexity, etc."
      ],
      "metadata": {
        "id": "okj6x_38VR8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data ###"
      ],
      "metadata": {
        "id": "i1MjkuLCST5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_subsets(train_dataset, test_dataset, subset_ratio):\n",
        "    train_subset_size = int(len(train_dataset) * (subset_ratio / 100))\n",
        "    train_subset_indices = np.random.choice(len(train_dataset), train_subset_size, replace=False)\n",
        "    train_subset = Subset(train_dataset, train_subset_indices)\n",
        "    test_subset_size = int(len(test_dataset) * (subset_ratio / 100))\n",
        "    test_subset_indices = np.random.choice(len(test_dataset), test_subset_size, replace=False)\n",
        "    test_subset = Subset(test_dataset, test_subset_indices)\n",
        "    return train_subset, test_subset\n",
        "\n",
        "\n",
        "def load_MNIST(batch_size, subset_ratio=None):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    # Load full training and testing dataset\n",
        "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    # Print dataset sizes\n",
        "    print(f\"Full training dataset size: {len(train_dataset)}\")\n",
        "    print(f\"Full testing dataset size: {len(test_dataset)}\")\n",
        "\n",
        "    # Load subset if required\n",
        "    if subset_ratio is not None:\n",
        "        train_subset, test_subset = create_subsets(train_dataset, test_dataset, subset_ratio)\n",
        "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=True)\n",
        "    else:\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "vfqezaJ-SV7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_ImageNet():\n",
        "    url='http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
        "    download_dir = os.getcwd()\n",
        "    dataset_dir = os.path.join(download_dir, 'tiny-imagenet-200')\n",
        "    if os.path.exists(dataset_dir):\n",
        "        return dataset_dir\n",
        "\n",
        "    print(\"Downloading Tiny ImageNet dataset...\")\n",
        "    tiny_imgdataset_path = wget.download(url, out=download_dir)\n",
        "    print(f\"\\nDownloaded to: {tiny_imgdataset_path}\")\n",
        "\n",
        "    print(\"Extracting dataset...\")\n",
        "    with ZipFile(tiny_imgdataset_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(download_dir)\n",
        "    print(\"Extraction complete.\")\n",
        "\n",
        "    os.remove(tiny_imgdataset_path)\n",
        "    print(f\"Deleted the zip file: {tiny_imgdataset_path}\")\n",
        "    return dataset_dir\n",
        "\n",
        "\n",
        "class TinyImageNetLoader:\n",
        "    def __init__(self, data_dir, batch_size=32, img_size=28, subset_ratio=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.subset_ratio = subset_ratio\n",
        "        self.img_size = img_size\n",
        "        self.train_dir = os.path.join(data_dir, 'train')\n",
        "        self.val_dir = os.path.join(data_dir, 'val')\n",
        "        self.val_images_dir = os.path.join(self.val_dir, 'images')\n",
        "        self.val_annotations_path = os.path.join(self.val_dir, 'val_annotations.txt')\n",
        "\n",
        "    def _load_val_annotations(self):\n",
        "        val_annotations = {}\n",
        "        with open(self.val_annotations_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split('\\t')\n",
        "                img_name = parts[0]\n",
        "                class_id = parts[1]\n",
        "                val_annotations[img_name] = class_id\n",
        "        return val_annotations\n",
        "\n",
        "    def _get_transforms(self):\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize(self.img_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def _create_val_dataset(self, annotations):\n",
        "        val_images = []\n",
        "        val_labels = []\n",
        "        for img_name, true_label in annotations.items():\n",
        "            img_path = os.path.join(self.val_images_dir, img_name)\n",
        "            if isinstance(img_path, str):\n",
        "                try:\n",
        "                    img = Image.open(img_path).convert('RGB')\n",
        "                    val_images.append(img)\n",
        "                    val_labels.append(true_label)\n",
        "                except (UnidentifiedImageError, IOError) as e:\n",
        "                    print(f\"Error opening image {img_path}: {e}\")\n",
        "                    continue\n",
        "            else:\n",
        "                print(f\"Skipping invalid image path: {img_path}\")\n",
        "\n",
        "            val_images.append(img)\n",
        "            val_labels.append(true_label)\n",
        "        return val_images, val_labels\n",
        "\n",
        "    def _encode_labels(self, val_labels):\n",
        "        class_names = sorted(os.listdir(self.train_dir))\n",
        "        label_mapping = {name: idx for idx, name in enumerate(class_names)}\n",
        "        return [label_mapping[label] for label in val_labels]\n",
        "\n",
        "    def load_data(self):\n",
        "        # Load train dataset using ImageFolder\n",
        "        train_transform = self._get_transforms()\n",
        "        train_dataset = ImageFolder(root=self.train_dir, transform=train_transform)\n",
        "\n",
        "        # Load validation dataset manually\n",
        "        val_annotations = self._load_val_annotations()\n",
        "        val_images, val_labels = self._create_val_dataset(val_annotations)\n",
        "        val_labels_encoded = self._encode_labels(val_labels)\n",
        "\n",
        "        # Create validation dataset\n",
        "        val_dataset = torch.utils.data.TensorDataset(\n",
        "            torch.stack([train_transform(img) for img in val_images]),\n",
        "            torch.tensor(val_labels_encoded)\n",
        "        )\n",
        "\n",
        "        # DataLoaders\n",
        "        print(f\"Full training dataset size: {len(train_dataset)}\")\n",
        "        print(f\"Full testing dataset size: {len(val_dataset)}\")\n",
        "        if self.subset_ratio is not None:\n",
        "            train_subset, val_subset = create_subsets(train_dataset, val_dataset, self.subset_ratio)\n",
        "            train_loader = DataLoader(train_subset, batch_size=self.batch_size, shuffle=True)\n",
        "            val_loader = DataLoader(val_subset, batch_size=self.batch_size, shuffle=True)\n",
        "        else:\n",
        "            train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        return train_loader, val_loader"
      ],
      "metadata": {
        "id": "Ytv0DniDOk8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_CIFAR(batch_size=32, img_size=28, subset_ratio=None):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(img_size),\n",
        "        transforms.Grayscale(num_output_channels=1),  # convert to grayscale\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "    ])\n",
        "\n",
        "    train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    print(f\"Full training dataset size: {len(train_dataset)}\")\n",
        "    print(f\"Full testing dataset size: {len(test_dataset)}\")\n",
        "\n",
        "    if subset_ratio is not None:\n",
        "        train_subset, test_subset = create_subsets(train_dataset, test_dataset, subset_ratio)\n",
        "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=True)\n",
        "    else:\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "5nlMO7A_h-jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Configurations ###"
      ],
      "metadata": {
        "id": "hz9wU4DQ-Xiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Configuration\n",
        "wb = {'project': 'CSC413', 'run': 'caps-hebb-softmax-lr0.001'}\n",
        "wb_ImageNet = {'project': 'CSC413', 'run': 'ImageNet-caps-hebb-softmax-lr0.001'}\n",
        "wb_CIFAR = {'project': 'CSC413', 'run': 'CIFAR-caps-hebb-softmax-lr0.001'}\n",
        "\n",
        "cfg = {\n",
        "    \"classes\": 10,\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 50,\n",
        "    \"lr\": 0.001,\n",
        "    \"lr_decay\": 0.9,\n",
        "    \"lam_recon\": 0.0005 * 784,\n",
        "    \"routings\": 3,\n",
        "    \"save_dir\": \"./log\",\n",
        "    \"wb\": wb\n",
        "}\n",
        "\n",
        "cfg_ImageNet = {\n",
        "    \"classes\": 200,\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 50,\n",
        "    \"lr\": 0.001,\n",
        "    \"lr_decay\": 0.9,\n",
        "    \"lam_recon\": 0.0005 * 784,\n",
        "    \"routings\": 3,\n",
        "    \"save_dir\": \"./log\",\n",
        "    \"wb\": wb_ImageNet\n",
        "}\n",
        "\n",
        "cfg_CIFAR = {\n",
        "    \"classes\": 100,\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 50,\n",
        "    \"lr\": 0.001,\n",
        "    \"lr_decay\": 0.9,\n",
        "    \"lam_recon\": 0.0005 * 784,\n",
        "    \"routings\": 3,\n",
        "    \"save_dir\": \"./log\",\n",
        "    \"wb\": wb_CIFAR\n",
        "}\n",
        "\n",
        "# Logging directory\n",
        "if not os.path.exists(cfg[\"save_dir\"]):\n",
        "    os.makedirs(cfg[\"save_dir\"])\n",
        "\n",
        "### Datasets\n",
        "# MNIST\n",
        "train_MNIST, test_MNIST = load_MNIST(cfg[\"batch_size\"], subset_ratio=0.1)\n",
        "\n",
        "# # TinyImageNet\n",
        "# dataset_dir = download_ImageNet()\n",
        "# loader = TinyImageNetLoader(data_dir=dataset_dir, batch_size=cfg_ImageNet[\"batch_size\"], subset_ratio=0.1)\n",
        "# train_ImageNet, test_ImageNet = loader.load_data()\n",
        "\n",
        "# # CIFAR100\n",
        "# train_CIFAR, test_CIFAR = load_CIFAR(cfg[\"batch_size\"], subset_ratio=0.1)"
      ],
      "metadata": {
        "id": "SMuHWpnGJKIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f84ed2e1-9254-4500-c4d3-4ad2f6f76fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 54.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 1.77MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 14.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 9.37MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Full training dataset size: 60000\n",
            "Full testing dataset size: 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results ###"
      ],
      "metadata": {
        "id": "HmfS0zRD-ez3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = {\n",
        "    \"classes\": 10,\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 10,\n",
        "    \"lr\": 0.001,\n",
        "    \"lr_decay\": 0.9,\n",
        "    \"lam_recon\": 0.0005 * 784,\n",
        "    \"routings\": 3,\n",
        "    \"save_dir\": \"./log\",\n",
        "    \"wb\": wb\n",
        "}\n",
        "\n",
        "cfg_ImageNet = {\n",
        "    \"classes\": 200,\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 50,\n",
        "    \"lr\": 0.001,\n",
        "    \"lr_decay\": 0.9,\n",
        "    \"lam_recon\": 0.0005 * 784,\n",
        "    \"routings\": 3,\n",
        "    \"save_dir\": \"./log\",\n",
        "    \"wb\": wb_ImageNet\n",
        "}\n",
        "\n",
        "cfg_CIFAR = {\n",
        "    \"classes\": 100,\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 50,\n",
        "    \"lr\": 0.001,\n",
        "    \"lr_decay\": 0.9,\n",
        "    \"lam_recon\": 0.0005 * 784,\n",
        "    \"routings\": 3,\n",
        "    \"save_dir\": \"./log\",\n",
        "    \"wb\": wb_CIFAR\n",
        "}"
      ],
      "metadata": {
        "id": "fJqKgpHiLE_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## MNIST\n",
        "print(\"MNIST\")\n",
        "# print(\"CapsNet\")\n",
        "debug=True\n",
        "capsnet = CapsuleNet(input_size=[1, 28, 28], classes=cfg[\"classes\"], routings=cfg[\"routings\"])\n",
        "# train(capsnet, train_MNIST, test_MNIST, cfg)\n",
        "\n",
        "# print(\"CapsNet + Hebbian\")\n",
        "train_hebb(capsnet, train_MNIST, test_MNIST, cfg)\n",
        "\n",
        "# ## TinyImageNet\n",
        "# print(\"TinyImageNet-200\")\n",
        "# print(\"CapsNet\")\n",
        "# capsnet = CapsuleNet(input_size=[1, 28, 28], classes=cfg_ImageNet[\"classes\"], routings=cfg_ImageNet[\"routings\"])\n",
        "# train(capsnet, train_MNIST, test_MNIST, cfg_ImageNet)\n",
        "\n",
        "# print(\"CapsNet + Hebbian\")\n",
        "# train_hebb(capsnet, train_MNIST, test_MNIST, cfg_ImageNet)\n",
        "\n",
        "# ## CIFAR100\n",
        "# print(\"CIFAR100\")\n",
        "# print(\"CapsNet\")\n",
        "# capsnet = CapsuleNet(input_size=[1, 28, 28], classes=cfg_CIFAR[\"classes\"], routings=cfg_CIFAR[\"routings\"])\n",
        "# train(capsnet, train_CIFAR, test_CIFAR, cfg_CIFAR)\n",
        "\n",
        "# print(\"CapsNet + Hebbian\")\n",
        "# train_hebb(capsnet, train_CIFAR, test_CIFAR, cfg_CIFAR)\n",
        "\n",
        "# ## Extra: CapsNet + HebbianSoftmax\n",
        "# capsnet_softmax = CapsuleNet(input_size=[1, 28, 28], classes=cfg[\"classes\"], routings=cfg[\"routings\"], softmax=True)\n",
        "# train(capsnet_softmax, train_MNIST, test_MNIST, cfg)"
      ],
      "metadata": {
        "id": "mnOWRMACVqK5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9e5e31436d754c43ad6bc34ddb9617cf",
            "843f1379624d45958e9b1936a7cdb6bd",
            "ec1d6944e27f4571a9de657b18438697",
            "3714955f3f6946d4869405d26137c4dc",
            "dd9893bf8f654c49bceb93474549a0df",
            "03b78c354b8e48bfa87c25099205f8d9",
            "107439f0da374544be084a11d99c9467",
            "7fa0d3c11d9f441c973b7498c3ba7e14"
          ]
        },
        "outputId": "5c35848d-0a6e-4214-fdb1-06d8b85c303e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST\n",
            "Training starts...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241212_021251-e6vvuku6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/taliafabs-university-of-toronto/CSC413/runs/e6vvuku6' target=\"_blank\">caps-hebb-softmax-lr0.001</a></strong> to <a href='https://wandb.ai/taliafabs-university-of-toronto/CSC413' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/taliafabs-university-of-toronto/CSC413' target=\"_blank\">https://wandb.ai/taliafabs-university-of-toronto/CSC413</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/taliafabs-university-of-toronto/CSC413/runs/e6vvuku6' target=\"_blank\">https://wandb.ai/taliafabs-university-of-toronto/CSC413/runs/e6vvuku6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([4, 10])\n",
            "Input shape: torch.Size([4, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([4, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([4, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([4, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([4, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([4, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([4, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([4, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([4, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([4, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([4, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([4, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([4, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([4, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([4, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([4, 784])\n",
            "Decoder Output shape: torch.Size([4, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([4, 512])\n",
            "Shape of error: torch.Size([4, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([4, 1024])\n",
            "Shape of error: torch.Size([4, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Input shape: torch.Size([2, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([2, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([2, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([2, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([2, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([2, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([2, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([2, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([2, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([2, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([2, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([2, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([2, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([2, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([2, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([2, 784])\n",
            "Decoder Output shape: torch.Size([2, 784])\n",
            "train: epoch = 0, loss = 1.4299, classfication acc = 0.1833, reconstruction err = 1.1101\n",
            "                   precision = 0.1881, recall = 0.1833, f1-score = 0.1777\n",
            "test: epoch = 0, loss = 1.2168, classfication acc = 0.3000, reconstruction err = 1.0208\n",
            "                  precision = 0.4125, recall = 0.3000, f1-score = 0.2889\n",
            "Epoch: 1\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([4, 10])\n",
            "Input shape: torch.Size([4, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([4, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([4, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([4, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([4, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([4, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([4, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([4, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([4, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([4, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([4, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([4, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([4, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([4, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([4, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([4, 784])\n",
            "Decoder Output shape: torch.Size([4, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([4, 512])\n",
            "Shape of error: torch.Size([4, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([4, 1024])\n",
            "Shape of error: torch.Size([4, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Input shape: torch.Size([2, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([2, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([2, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([2, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([2, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([2, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([2, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([2, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([2, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([2, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([2, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([2, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([2, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([2, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([2, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([2, 784])\n",
            "Decoder Output shape: torch.Size([2, 784])\n",
            "train: epoch = 1, loss = 1.0995, classfication acc = 0.6000, reconstruction err = 0.9910\n",
            "                   precision = 0.6367, recall = 0.6000, f1-score = 0.5936\n",
            "test: epoch = 1, loss = 1.0246, classfication acc = 0.6000, reconstruction err = 0.9514\n",
            "                  precision = 0.6000, recall = 0.6000, f1-score = 0.6000\n",
            "Epoch: 2\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([4, 10])\n",
            "Input shape: torch.Size([4, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([4, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([4, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([4, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([4, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([4, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([4, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([4, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([4, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([4, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([4, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([4, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([4, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([4, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([4, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([4, 784])\n",
            "Decoder Output shape: torch.Size([4, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([4, 512])\n",
            "Shape of error: torch.Size([4, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([4, 1024])\n",
            "Shape of error: torch.Size([4, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Input shape: torch.Size([2, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([2, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([2, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([2, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([2, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([2, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([2, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([2, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([2, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([2, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([2, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([2, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([2, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([2, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([2, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([2, 784])\n",
            "Decoder Output shape: torch.Size([2, 784])\n",
            "train: epoch = 2, loss = 0.9987, classfication acc = 0.7667, reconstruction err = 0.9421\n",
            "                   precision = 0.7889, recall = 0.7667, f1-score = 0.7414\n",
            "test: epoch = 2, loss = 0.9021, classfication acc = 0.8000, reconstruction err = 0.9274\n",
            "                  precision = 0.8500, recall = 0.8000, f1-score = 0.8000\n",
            "Epoch: 3\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([4, 10])\n",
            "Input shape: torch.Size([4, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([4, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([4, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([4, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([4, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([4, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([4, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([4, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([4, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([4, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([4, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([4, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([4, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([4, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([4, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([4, 784])\n",
            "Decoder Output shape: torch.Size([4, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([4, 512])\n",
            "Shape of error: torch.Size([4, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([4, 1024])\n",
            "Shape of error: torch.Size([4, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Input shape: torch.Size([2, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([2, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([2, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([2, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([2, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([2, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([2, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([2, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([2, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([2, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([2, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([2, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([2, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([2, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([2, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([2, 784])\n",
            "Decoder Output shape: torch.Size([2, 784])\n",
            "train: epoch = 3, loss = 0.8714, classfication acc = 0.9667, reconstruction err = 0.9236\n",
            "                   precision = 0.9711, recall = 0.9667, f1-score = 0.9654\n",
            "test: epoch = 3, loss = 0.8948, classfication acc = 0.8000, reconstruction err = 0.9170\n",
            "                  precision = 0.8000, recall = 0.8000, f1-score = 0.8000\n",
            "Epoch: 4\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([4, 10])\n",
            "Input shape: torch.Size([4, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([4, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([4, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([4, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([4, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([4, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([4, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([4, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([4, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([4, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([4, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([4, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([4, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([4, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([4, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([4, 784])\n",
            "Decoder Output shape: torch.Size([4, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([4, 512])\n",
            "Shape of error: torch.Size([4, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([4, 1024])\n",
            "Shape of error: torch.Size([4, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Input shape: torch.Size([2, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([2, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([2, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([2, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([2, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([2, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([2, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([2, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([2, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([2, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([2, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([2, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([2, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([2, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([2, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([2, 784])\n",
            "Decoder Output shape: torch.Size([2, 784])\n",
            "train: epoch = 4, loss = 0.8337, classfication acc = 0.9667, reconstruction err = 0.9112\n",
            "                   precision = 0.9711, recall = 0.9667, f1-score = 0.9659\n",
            "test: epoch = 4, loss = 0.8551, classfication acc = 0.9000, reconstruction err = 0.9053\n",
            "                  precision = 0.8500, recall = 0.9000, f1-score = 0.8667\n",
            "Epoch: 5\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([4, 10])\n",
            "Input shape: torch.Size([4, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([4, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([4, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([4, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([4, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([4, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([4, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([4, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([4, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([4, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([4, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([4, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([4, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([4, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([4, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([4, 784])\n",
            "Decoder Output shape: torch.Size([4, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([4, 512])\n",
            "Shape of error: torch.Size([4, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([4, 1024])\n",
            "Shape of error: torch.Size([4, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Input shape: torch.Size([2, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([2, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([2, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([2, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([2, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([2, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([2, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([2, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([2, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([2, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([2, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([2, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([2, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([2, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([2, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([2, 784])\n",
            "Decoder Output shape: torch.Size([2, 784])\n",
            "train: epoch = 5, loss = 0.7917, classfication acc = 1.0000, reconstruction err = 0.9041\n",
            "                   precision = 1.0000, recall = 1.0000, f1-score = 1.0000\n",
            "test: epoch = 5, loss = 0.8376, classfication acc = 0.9000, reconstruction err = 0.9024\n",
            "                  precision = 0.8500, recall = 0.9000, f1-score = 0.8667\n",
            "Epoch: 6\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([4, 10])\n",
            "Input shape: torch.Size([4, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([4, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([4, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([4, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([4, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([4, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([4, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([4, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([4, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([4, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([4, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([4, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([4, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([4, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([4, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([4, 784])\n",
            "Decoder Output shape: torch.Size([4, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([4, 512])\n",
            "Shape of error: torch.Size([4, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([4, 1024])\n",
            "Shape of error: torch.Size([4, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Input shape: torch.Size([2, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([2, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([2, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([2, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([2, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([2, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([2, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([2, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([2, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([2, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([2, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([2, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([2, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([2, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([2, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([2, 784])\n",
            "Decoder Output shape: torch.Size([2, 784])\n",
            "train: epoch = 6, loss = 0.7759, classfication acc = 1.0000, reconstruction err = 0.8989\n",
            "                   precision = 1.0000, recall = 1.0000, f1-score = 1.0000\n",
            "test: epoch = 6, loss = 0.8515, classfication acc = 0.9000, reconstruction err = 0.8921\n",
            "                  precision = 0.8500, recall = 0.9000, f1-score = 0.8667\n",
            "Epoch: 7\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([4, 10])\n",
            "Input shape: torch.Size([4, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([4, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([4, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([4, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([4, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([4, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([4, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([4, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([4, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([4, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([4, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([4, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([4, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([4, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([4, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([4, 784])\n",
            "Decoder Output shape: torch.Size([4, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([4, 512])\n",
            "Shape of error: torch.Size([4, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([4, 1024])\n",
            "Shape of error: torch.Size([4, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Input shape: torch.Size([2, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([2, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([2, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([2, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([2, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([2, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([2, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([2, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([2, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([2, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([2, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([2, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([2, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([2, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([2, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([2, 784])\n",
            "Decoder Output shape: torch.Size([2, 784])\n",
            "train: epoch = 7, loss = 0.7660, classfication acc = 1.0000, reconstruction err = 0.8950\n",
            "                   precision = 1.0000, recall = 1.0000, f1-score = 1.0000\n",
            "test: epoch = 7, loss = 0.8347, classfication acc = 0.8000, reconstruction err = 0.8869\n",
            "                  precision = 0.7833, recall = 0.8000, f1-score = 0.7600\n",
            "Epoch: 8\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([4, 10])\n",
            "Input shape: torch.Size([4, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([4, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([4, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([4, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([4, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([4, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([4, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([4, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([4, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([4, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([4, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([4, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([4, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([4, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([4, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([4, 784])\n",
            "Decoder Output shape: torch.Size([4, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([4, 512])\n",
            "Shape of error: torch.Size([4, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([4, 1024])\n",
            "Shape of error: torch.Size([4, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Input shape: torch.Size([2, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([2, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([2, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([2, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([2, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([2, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([2, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([2, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([2, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([2, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([2, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([2, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([2, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([2, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([2, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([2, 784])\n",
            "Decoder Output shape: torch.Size([2, 784])\n",
            "train: epoch = 8, loss = 0.7561, classfication acc = 1.0000, reconstruction err = 0.8922\n",
            "                   precision = 1.0000, recall = 1.0000, f1-score = 1.0000\n",
            "test: epoch = 8, loss = 0.8423, classfication acc = 0.8000, reconstruction err = 0.8957\n",
            "                  precision = 0.7833, recall = 0.8000, f1-score = 0.7600\n",
            "Epoch: 9\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([8, 10])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([8, 512])\n",
            "Shape of error: torch.Size([8, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([8, 1024])\n",
            "Shape of error: torch.Size([8, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "One-hot Encoding y: torch.Size([4, 10])\n",
            "Input shape: torch.Size([4, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([4, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([4, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([4, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([4, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([4, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([4, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([4, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([4, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([4, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([4, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([4, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([4, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([4, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([4, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([4, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([4, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([4, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([4, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([4, 784])\n",
            "Decoder Output shape: torch.Size([4, 784])\n",
            "Layer: conv1.weight, Shape of theta: torch.Size([256, 1, 9, 9])\n",
            "Layer: conv1.bias, Shape of theta: torch.Size([256])\n",
            "Layer: primarycaps.conv2d.weight, Shape of theta: torch.Size([256, 256, 9, 9])\n",
            "Layer: primarycaps.conv2d.bias, Shape of theta: torch.Size([256])\n",
            "Layer: digitcaps.weight, Shape of theta: torch.Size([10, 1152, 16, 8])\n",
            "Layer: decoder.fc1.weight, Shape of theta: torch.Size([512, 160])\n",
            "Layer: decoder.fc1.bias, Shape of theta: torch.Size([512])\n",
            "Layer: decoder.fc2.weight, Shape of theta: torch.Size([1024, 512])\n",
            "Shape of h: torch.Size([4, 512])\n",
            "Shape of error: torch.Size([4, 1024])\n",
            "Shape of gradient: torch.Size([1024, 512])\n",
            "Shape of theta_0.5: torch.Size([1024, 512])\n",
            "Shape of h_bar_t: torch.Size([1024, 512])\n",
            "Shape of updated theta: torch.Size([1024, 512])\n",
            "Layer: decoder.fc2.bias, Shape of theta: torch.Size([1024])\n",
            "Layer: decoder.fc3.weight, Shape of theta: torch.Size([784, 1024])\n",
            "Shape of h: torch.Size([4, 1024])\n",
            "Shape of error: torch.Size([4, 784])\n",
            "Shape of gradient: torch.Size([784, 1024])\n",
            "Shape of theta_0.5: torch.Size([784, 1024])\n",
            "Shape of h_bar_t: torch.Size([784, 1024])\n",
            "Shape of updated theta: torch.Size([784, 1024])\n",
            "Layer: decoder.fc3.bias, Shape of theta: torch.Size([784])\n",
            "Input shape: torch.Size([8, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([8, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([8, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([8, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([8, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([8, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([8, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([8, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([8, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([8, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([8, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([8, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([8, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([8, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([8, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([8, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([8, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([8, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([8, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([8, 784])\n",
            "Decoder Output shape: torch.Size([8, 784])\n",
            "Input shape: torch.Size([2, 1, 28, 28])\n",
            "Hook triggered for conv1, activation shape: torch.Size([2, 256, 20, 20])\n",
            "Conv1 Output shape: torch.Size([2, 256, 20, 20])\n",
            "ReLU Ouput shape: torch.Size([2, 256, 20, 20])\n",
            "PrimaryCapsule Input shape: torch.Size([2, 256, 20, 20])\n",
            "Hook triggered for primarycaps.conv2d, activation shape: torch.Size([2, 256, 6, 6])\n",
            "After Conv2D shape: torch.Size([2, 256, 6, 6])\n",
            "PrimaryCapsule Output shape: torch.Size([2, 1152, 8])\n",
            "Hook triggered for primarycaps, activation shape: torch.Size([2, 1152, 8])\n",
            "DigitCapsule Input shape: torch.Size([2, 1152, 8])\n",
            "After reshape for routing shape: torch.Size([2, 1, 1152, 8, 1])\n",
            "x_hat shape: torch.Size([2, 10, 1152, 16])\n",
            "Routing 1 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 2 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "Routing 3 coupling coefficients shape: torch.Size([2, 10, 1152])\n",
            "DigitCapsule Output shape: torch.Size([2, 10, 1, 16])\n",
            "Hook triggered for digitcaps, activation shape: torch.Size([2, 10, 16])\n",
            "Length shape (class probabilities): torch.Size([2, 10])\n",
            "Hook triggered for decoder.fc1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.relu1, activation shape: torch.Size([2, 512])\n",
            "Hook triggered for decoder.fc2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.relu2, activation shape: torch.Size([2, 1024])\n",
            "Hook triggered for decoder.fc3, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder.sigmoid, activation shape: torch.Size([2, 784])\n",
            "Hook triggered for decoder, activation shape: torch.Size([2, 784])\n",
            "Decoder Output shape: torch.Size([2, 784])\n",
            "train: epoch = 9, loss = 0.7513, classfication acc = 1.0000, reconstruction err = 0.8878\n",
            "                   precision = 1.0000, recall = 1.0000, f1-score = 1.0000\n",
            "test: epoch = 9, loss = 0.8403, classfication acc = 0.8000, reconstruction err = 0.8899\n",
            "                  precision = 0.7833, recall = 0.8000, f1-score = 0.7600\n",
            "Training Finished\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.264 MB of 0.264 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e5e31436d754c43ad6bc34ddb9617cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡</td></tr><tr><td>test_f1</td><td>â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡</td></tr><tr><td>test_loss</td><td>â–ˆâ–„â–‚â–‚â–â–â–â–â–â–</td></tr><tr><td>test_precision</td><td>â–â–„â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡</td></tr><tr><td>test_recall</td><td>â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡</td></tr><tr><td>test_recon_err</td><td>â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–</td></tr><tr><td>train_acc</td><td>â–â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_f1</td><td>â–â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–…â–„â–‚â–‚â–â–â–â–â–</td></tr><tr><td>train_precision</td><td>â–â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_recall</td><td>â–â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_recon_err</td><td>â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>0.8</td></tr><tr><td>test_f1</td><td>0.76</td></tr><tr><td>test_loss</td><td>0.84035</td></tr><tr><td>test_precision</td><td>0.78333</td></tr><tr><td>test_recall</td><td>0.8</td></tr><tr><td>test_recon_err</td><td>0.88992</td></tr><tr><td>train_acc</td><td>1</td></tr><tr><td>train_f1</td><td>1</td></tr><tr><td>train_loss</td><td>0.75131</td></tr><tr><td>train_precision</td><td>1</td></tr><tr><td>train_recall</td><td>1</td></tr><tr><td>train_recon_err</td><td>0.88782</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">caps-hebb-softmax-lr0.001</strong> at: <a href='https://wandb.ai/taliafabs-university-of-toronto/CSC413/runs/e6vvuku6' target=\"_blank\">https://wandb.ai/taliafabs-university-of-toronto/CSC413/runs/e6vvuku6</a><br/> View project at: <a href='https://wandb.ai/taliafabs-university-of-toronto/CSC413' target=\"_blank\">https://wandb.ai/taliafabs-university-of-toronto/CSC413</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241212_021251-e6vvuku6/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CapsuleNet(\n",
              "  (conv1): Conv2d(1, 256, kernel_size=(9, 9), stride=(1, 1))\n",
              "  (primarycaps): PrimaryCapsule(\n",
              "    (conv2d): Conv2d(256, 256, kernel_size=(9, 9), stride=(2, 2))\n",
              "  )\n",
              "  (digitcaps): DigitCapsule()\n",
              "  (decoder): Sequential(\n",
              "    (fc1): Linear(in_features=160, out_features=512, bias=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (fc2): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    (relu2): ReLU(inplace=True)\n",
              "    (fc3): Linear(in_features=1024, out_features=784, bias=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## CNN autoencoder\n",
        "debug=False\n",
        "cnn_wb = {'project': 'CSC413', 'run': 'cnn-lr0.001'}\n",
        "cnn_hebb_wb = {'project': 'CSC413', 'run': 'cnn-hebb-softmax-lr0.001'}\n",
        "cnn_cfg = {\n",
        "    \"classes\": 10,\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 50,\n",
        "    \"lr\": 0.001,\n",
        "    \"lr_decay\": 0.9,\n",
        "    \"lam_recon\": 0.0005 * 784,\n",
        "    \"routings\": 3,\n",
        "    \"save_dir\": \"./log\",\n",
        "    \"wb\": cnn_wb\n",
        "}\n",
        "cnn_hebb_cfg = {\n",
        "    \"classes\": 10,\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 50,\n",
        "    \"lr\": 0.001,\n",
        "    \"lr_decay\": 0.9,\n",
        "    \"lam_recon\": 0.0005 * 784,\n",
        "    \"routings\": 3,\n",
        "    \"save_dir\": \"./log\",\n",
        "    \"wb\": cnn_hebb_wb\n",
        "}\n",
        "cnn = CNNAutoencoder(input_size=[1, 28, 28], classes=cfg[\"classes\"], softmax=False)\n",
        "train(cnn, train_MNIST, test_MNIST, cnn_cfg)\n",
        "\n",
        "cnn_hebb = CNNAutoencoder(input_size=[1, 28, 28], classes=cfg[\"classes\"], softmax=True)\n",
        "train(cnn_hebb, train_MNIST, test_MNIST, cnn_hebb_cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kfwczVTouXDZ",
        "outputId": "3a5af604-e9de-41b7-ce49-974c9d5c38ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training starts...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241212_072212-sw1jlj7h</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/trimunculo-oxygenate/CSC413/runs/sw1jlj7h' target=\"_blank\">cnn-lr0.001</a></strong> to <a href='https://wandb.ai/trimunculo-oxygenate/CSC413' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/trimunculo-oxygenate/CSC413' target=\"_blank\">https://wandb.ai/trimunculo-oxygenate/CSC413</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/trimunculo-oxygenate/CSC413/runs/sw1jlj7h' target=\"_blank\">https://wandb.ai/trimunculo-oxygenate/CSC413/runs/sw1jlj7h</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: epoch = 0, loss = 1.5359, classfication acc = 0.0667, reconstruction err = 0.5224\n",
            "                   precision = 0.0201, recall = 0.0667, f1-score = 0.0257\n",
            "test: epoch = 0, loss = 1.2130, classfication acc = 0.3000, reconstruction err = 0.4695\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 1, loss = 1.4573, classfication acc = 0.1000, reconstruction err = 0.4575\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 1, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4395\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 2, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4425\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 2, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4678\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 3, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4490\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 3, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4581\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 4, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4570\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 4, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4436\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 5, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4517\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 5, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4709\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 6, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4455\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 6, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4114\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 7, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4540\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 7, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4401\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 8, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4413\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 8, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4751\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 9, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4523\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 9, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4854\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 10, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4490\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 10, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4763\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 11, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4404\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 11, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.3985\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 12, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4520\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 12, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4308\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 13, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4412\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 13, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4763\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 14, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4490\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 14, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.5023\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 15, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4586\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 15, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4304\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 16, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4432\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 16, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4437\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 17, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4509\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 17, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4262\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 18, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4470\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 18, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4678\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 19, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4568\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 19, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4360\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 20, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4580\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 20, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4585\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 21, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4497\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 21, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4585\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 22, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4505\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 22, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4837\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 23, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4454\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 23, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4076\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 24, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4569\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 24, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4404\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 25, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4492\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 25, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4399\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 26, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4434\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 26, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4622\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 27, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4446\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 27, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4751\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 28, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4443\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 28, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4705\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 29, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4448\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 29, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4437\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 30, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4434\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 30, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4581\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 31, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4387\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 31, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4530\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 32, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4537\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 32, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4530\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 33, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4430\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 33, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4262\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 34, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4437\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 34, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4404\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 35, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4582\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 35, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4360\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 36, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4585\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 36, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4709\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 37, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4458\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 37, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.3948\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 38, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4524\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 38, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4713\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 39, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4515\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 39, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4114\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 40, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4526\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 40, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4114\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 41, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4464\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 41, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4433\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 42, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4551\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 42, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4267\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 43, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4506\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 43, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4404\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 44, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4501\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 44, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4364\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 45, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4461\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 45, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4360\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 46, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4489\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 46, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4581\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 47, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4449\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 47, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4802\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 48, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4487\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 48, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4041\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "train: epoch = 49, loss = 1.4577, classfication acc = 0.1000, reconstruction err = 0.4560\n",
            "                   precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "test: epoch = 49, loss = 1.2133, classfication acc = 0.3000, reconstruction err = 0.4364\n",
            "                  precision = 0.0900, recall = 0.3000, f1-score = 0.1385\n",
            "Training Finished\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>test_f1</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>test_loss</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>test_precision</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>test_recall</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>test_recon_err</td><td>â–†â–ƒâ–…â–…â–„â–â–ƒâ–†â–‡â–†â–ƒâ–ˆâ–ƒâ–„â–‚â–ƒâ–…â–…â–‡â–â–ƒâ–†â–†â–„â–…â–„â–‚â–ƒâ–ƒâ–†â–†â–â–â–„â–‚â–ƒâ–ƒâ–…â–†â–ƒ</td></tr><tr><td>train_acc</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_f1</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train_loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train_precision</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train_recall</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_recon_err</td><td>â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–â–â–â–â–â–‚â–â–â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>0.3</td></tr><tr><td>test_f1</td><td>0.13846</td></tr><tr><td>test_loss</td><td>1.21332</td></tr><tr><td>test_precision</td><td>0.09</td></tr><tr><td>test_recall</td><td>0.3</td></tr><tr><td>test_recon_err</td><td>0.43637</td></tr><tr><td>train_acc</td><td>0.1</td></tr><tr><td>train_f1</td><td>0.01818</td></tr><tr><td>train_loss</td><td>1.45769</td></tr><tr><td>train_precision</td><td>0.01</td></tr><tr><td>train_recall</td><td>0.1</td></tr><tr><td>train_recon_err</td><td>0.45605</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cnn-lr0.001</strong> at: <a href='https://wandb.ai/trimunculo-oxygenate/CSC413/runs/sw1jlj7h' target=\"_blank\">https://wandb.ai/trimunculo-oxygenate/CSC413/runs/sw1jlj7h</a><br/> View project at: <a href='https://wandb.ai/trimunculo-oxygenate/CSC413' target=\"_blank\">https://wandb.ai/trimunculo-oxygenate/CSC413</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241212_072212-sw1jlj7h/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33methanoate\u001b[0m (\u001b[33mtrimunculo-oxygenate\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training starts...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241212_072227-oh9dof6u</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/trimunculo-oxygenate/CSC413/runs/oh9dof6u' target=\"_blank\">cnn-hebb-softmax-lr0.001</a></strong> to <a href='https://wandb.ai/trimunculo-oxygenate/CSC413' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/trimunculo-oxygenate/CSC413' target=\"_blank\">https://wandb.ai/trimunculo-oxygenate/CSC413</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/trimunculo-oxygenate/CSC413/runs/oh9dof6u' target=\"_blank\">https://wandb.ai/trimunculo-oxygenate/CSC413/runs/oh9dof6u</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: epoch = 0, loss = 1.4525, classfication acc = 0.1333, reconstruction err = 0.5308\n",
            "                   precision = 0.1364, recall = 0.1333, f1-score = 0.1106\n",
            "test: epoch = 0, loss = 1.5772, classfication acc = 0.0000, reconstruction err = 0.4129\n",
            "                  precision = 0.0000, recall = 0.0000, f1-score = 0.0000\n",
            "train: epoch = 1, loss = 1.4972, classfication acc = 0.0667, reconstruction err = 0.4427\n",
            "                   precision = 0.0044, recall = 0.0667, f1-score = 0.0083\n",
            "test: epoch = 1, loss = 1.5772, classfication acc = 0.0000, reconstruction err = 0.4793\n",
            "                  precision = 0.0000, recall = 0.0000, f1-score = 0.0000\n",
            "train: epoch = 2, loss = 1.4156, classfication acc = 0.1167, reconstruction err = 0.4538\n",
            "                   precision = 0.0231, recall = 0.1167, f1-score = 0.0383\n",
            "test: epoch = 2, loss = 1.5772, classfication acc = 0.0000, reconstruction err = 0.4344\n",
            "                  precision = 0.0000, recall = 0.0000, f1-score = 0.0000\n",
            "train: epoch = 3, loss = 1.4341, classfication acc = 0.1000, reconstruction err = 0.4516\n",
            "                   precision = 0.0217, recall = 0.1000, f1-score = 0.0356\n",
            "test: epoch = 3, loss = 1.4540, classfication acc = 0.1000, reconstruction err = 0.3964\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 4, loss = 1.4564, classfication acc = 0.1000, reconstruction err = 0.4429\n",
            "                   precision = 0.0136, recall = 0.1000, f1-score = 0.0240\n",
            "test: epoch = 4, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4676\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 5, loss = 1.4724, classfication acc = 0.0833, reconstruction err = 0.4519\n",
            "                   precision = 0.0629, recall = 0.0833, f1-score = 0.0609\n",
            "test: epoch = 5, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4339\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 6, loss = 1.4768, classfication acc = 0.0833, reconstruction err = 0.4425\n",
            "                   precision = 0.0181, recall = 0.0833, f1-score = 0.0285\n",
            "test: epoch = 6, loss = 1.3342, classfication acc = 0.2000, reconstruction err = 0.4887\n",
            "                  precision = 0.0400, recall = 0.2000, f1-score = 0.0667\n",
            "train: epoch = 7, loss = 1.4715, classfication acc = 0.0667, reconstruction err = 0.4518\n",
            "                   precision = 0.0135, recall = 0.0667, f1-score = 0.0220\n",
            "test: epoch = 7, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4302\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 8, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4417\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 8, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4443\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 9, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4552\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 9, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4409\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 10, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4469\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 10, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4438\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 11, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4478\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 11, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4676\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 12, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4470\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 12, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4750\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 13, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4464\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 13, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4924\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 14, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4462\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 14, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4757\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 15, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4502\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 15, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4129\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 16, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4472\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 16, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4650\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 17, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4504\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 17, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.3964\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 18, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4408\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 18, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4750\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 19, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4496\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 19, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.5087\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 20, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4478\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 20, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4409\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 21, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4539\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 21, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4274\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 22, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4559\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 22, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4611\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 23, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4459\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 23, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4771\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 24, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4427\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 24, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4274\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 25, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4498\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 25, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4513\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 26, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4548\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 26, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4783\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 27, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4451\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 27, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4793\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 28, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4577\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 28, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4302\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 29, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4458\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 29, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4008\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 30, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4485\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 30, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4757\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 31, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4494\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 31, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4914\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 32, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4497\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 32, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4448\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 33, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4563\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 33, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4819\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 34, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4503\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 34, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.5194\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 35, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4457\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 35, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4783\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 36, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4501\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 36, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4445\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 37, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4526\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 37, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4819\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 38, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4456\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 38, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4448\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 39, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4495\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 39, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.3964\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 40, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4473\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 40, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4438\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 41, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4499\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 41, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4034\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 42, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4548\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 42, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4302\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 43, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4489\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 43, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4607\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 44, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4433\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 44, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4445\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 45, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4525\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 45, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4339\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 46, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4495\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 46, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4750\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 47, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4516\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 47, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4781\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 48, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4566\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 48, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4676\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "train: epoch = 49, loss = 1.4365, classfication acc = 0.1167, reconstruction err = 0.4442\n",
            "                   precision = 0.0136, recall = 0.1167, f1-score = 0.0244\n",
            "test: epoch = 49, loss = 1.4557, classfication acc = 0.1000, reconstruction err = 0.4317\n",
            "                  precision = 0.0100, recall = 0.1000, f1-score = 0.0182\n",
            "Training Finished\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>â–â–â–â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…</td></tr><tr><td>test_f1</td><td>â–â–â–â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ</td></tr><tr><td>test_loss</td><td>â–ˆâ–ˆâ–ˆâ–„â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…</td></tr><tr><td>test_precision</td><td>â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>test_recall</td><td>â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>test_recon_err</td><td>â–‚â–†â–ƒâ–â–…â–‡â–ƒâ–„â–„â–„â–†â–‡â–†â–‚â–…â–†â–ˆâ–„â–ƒâ–…â–ƒâ–„â–†â–†â–ƒâ–†â–‡â–„â–†â–†â–†â–„â–â–„â–â–…â–„â–ƒâ–†â–ƒ</td></tr><tr><td>train_acc</td><td>â–ˆâ–â–†â–„â–„â–ƒâ–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†</td></tr><tr><td>train_f1</td><td>â–ˆâ–â–ƒâ–‚â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚</td></tr><tr><td>train_loss</td><td>â–„â–ˆâ–â–ƒâ–†â–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ</td></tr><tr><td>train_precision</td><td>â–ˆâ–â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train_recall</td><td>â–ˆâ–â–†â–„â–ƒâ–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†</td></tr><tr><td>train_recon_err</td><td>â–ˆâ–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>0.1</td></tr><tr><td>test_f1</td><td>0.01818</td></tr><tr><td>test_loss</td><td>1.45571</td></tr><tr><td>test_precision</td><td>0.01</td></tr><tr><td>test_recall</td><td>0.1</td></tr><tr><td>test_recon_err</td><td>0.43173</td></tr><tr><td>train_acc</td><td>0.11667</td></tr><tr><td>train_f1</td><td>0.02438</td></tr><tr><td>train_loss</td><td>1.43649</td></tr><tr><td>train_precision</td><td>0.01361</td></tr><tr><td>train_recall</td><td>0.11667</td></tr><tr><td>train_recon_err</td><td>0.44418</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cnn-hebb-softmax-lr0.001</strong> at: <a href='https://wandb.ai/trimunculo-oxygenate/CSC413/runs/oh9dof6u' target=\"_blank\">https://wandb.ai/trimunculo-oxygenate/CSC413/runs/oh9dof6u</a><br/> View project at: <a href='https://wandb.ai/trimunculo-oxygenate/CSC413' target=\"_blank\">https://wandb.ai/trimunculo-oxygenate/CSC413</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241212_072227-oh9dof6u/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNAutoencoder(\n",
              "  (encoder): Sequential(\n",
              "    (0): Conv2d(1, 256, kernel_size=(9, 9), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(256, 256, kernel_size=(9, 9), stride=(2, 2))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Conv2d(256, 784, kernel_size=(6, 6), stride=(1, 1))\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (fc2): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    (relu2): ReLU(inplace=True)\n",
              "    (fc3): Linear(in_features=1024, out_features=784, bias=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=160, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (hebbsoftmax): HebbianSoftmax(\n",
              "    (linear): Linear(in_features=784, out_features=10, bias=False)\n",
              "    (softmax): Softmax(dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Other Ideas ##"
      ],
      "metadata": {
        "id": "jMN8n-tOh7ID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight Update Through Genetic Algorithm ###"
      ],
      "metadata": {
        "id": "ZbjenhCRjmOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pygad\n",
        "import pygad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5fkfTk0ekqCk",
        "outputId": "2d0edf5a-b53f-424d-83df-a3c405b008f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygad\n",
            "  Downloading pygad-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from pygad) (3.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pygad) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pygad) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->pygad) (1.16.0)\n",
            "Downloading pygad-3.3.1-py3-none-any.whl (84 kB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygad\n",
            "Successfully installed pygad-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness_function(ga_instance, solution, solution_idx):\n",
        "    \"\"\"Evaluate the fitness of a chromosome.\"\"\"\n",
        "    start = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        numel = param.numel()\n",
        "        param.data = torch.tensor(solution[start:start + numel], dtype=torch.float32).view(param.shape).to(DEVICE)\n",
        "        start += numel\n",
        "\n",
        "    model = model.to(torch.float32).to(DEVICE)\n",
        "    train_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.float().to(DEVICE), y.float().to(DEVICE)\n",
        "            y = torch.zeros(y.size(0), 10, device=DEVICE).scatter_(1, y.view(-1, 1), 1.)  # one-hot encoding\n",
        "            y_pred, x_recon = model(x)\n",
        "            loss = caps_loss(y, y_pred, x, x_recon, cfg[\"lam_recon\"])\n",
        "            train_loss += loss.item() * x.size(0)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    return -train_loss"
      ],
      "metadata": {
        "id": "OwnoKbKpjr0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyGAD setup\n",
        "num_generations = 50\n",
        "num_parents_mating = 5\n",
        "population_size = 10\n",
        "initial_weights = torch.cat([param.detach().view(-1) for param in model.parameters()]).cpu().numpy()\n",
        "num_weights = initial_weights.size\n",
        "\n",
        "# Initialize PyGAD\n",
        "ga_instance = pygad.GA(\n",
        "    num_generations=num_generations,\n",
        "    num_parents_mating=num_parents_mating,\n",
        "    fitness_func=fitness_function,\n",
        "    sol_per_pop=population_size,\n",
        "    num_genes=num_weights,\n",
        "    init_range_low=-1.0,  # Weight initialization range\n",
        "    init_range_high=1.0,\n",
        "    mutation_probability=0.1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "9aHsRUV9nrlG",
        "outputId": "94757def-00e8-44c7-cd44-5a2f1471e175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c5e0caf660ae>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_parents_mating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpopulation_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minitial_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnum_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CapsuleNet(nn.Module):\n",
        "    def __init__(self, input_size, classes, routings, hebb=True):\n",
        "        super(CapsuleNet, self).__init__()\n",
        "        self.hebb = hebb\n",
        "        self.input_size = input_size\n",
        "        self.classes = classes\n",
        "        self.routings = routings\n",
        "\n",
        "        self.conv1 = nn.Conv2d(input_size[0], 256, kernel_size=9, stride=1, padding=0, bias=False)\n",
        "        self.primarycaps = PrimaryCapsule(256, 256, 8, kernel_size=9, stride=2, padding=0, bias=False)\n",
        "        self.digitcaps = DigitCapsule(in_num_caps=32 * 6 * 6, in_dim_caps=8,\n",
        "                                      out_num_caps=classes, out_dim_caps=16, routings=routings)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            OrderedDict([\n",
        "                (\"fc1\", nn.Linear(16 * classes, 512, bias=False)),\n",
        "                (\"relu1\", nn.ReLU(inplace=True)),\n",
        "                (\"fc2\", nn.Linear(512, 1024, bias=False)),\n",
        "                (\"relu2\", nn.ReLU(inplace=True)),\n",
        "                (\"fc3\", nn.Linear(1024, input_size[0] * input_size[1] * input_size[2], bias=False)),\n",
        "                (\"sigmoid\", nn.Sigmoid())\n",
        "            ])\n",
        "        )\n",
        "        self.to(DEVICE)\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        x = x.to(DEVICE)\n",
        "        x = self.conv1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.primarycaps(x)\n",
        "        x = self.digitcaps(x)\n",
        "        length = x.norm(dim=-1)\n",
        "\n",
        "        if y is None:\n",
        "            index = length.max(dim=1)[1]\n",
        "            y = torch.zeros(length.size(), device=DEVICE).scatter_(1, index.view(-1, 1), 1.)\n",
        "\n",
        "        y = y.to(DEVICE)\n",
        "        reconstruction = self.decoder((x * y[:, :, None]).view(x.size(0), -1))\n",
        "        return length, reconstruction.view(-1, *self.input_size)\n",
        "\n",
        "\n",
        "class PrimaryCapsule(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dim_caps, kernel_size, stride=1, padding=0, bias=True):\n",
        "        super(PrimaryCapsule, self).__init__()\n",
        "        self.to(DEVICE)\n",
        "        self.dim_caps = dim_caps\n",
        "        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x.to(DEVICE)\n",
        "        outputs = self.conv2d(x)\n",
        "        outputs = outputs.view(x.size(0), -1, self.dim_caps)\n",
        "        return squash(outputs)"
      ],
      "metadata": {
        "id": "1yxM-NnKo4Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = load_data(cfg[\"batch_size\"], subset_ratio=0.1)\n",
        "model = CapsuleNet(input_size=[1, 28, 28], classes=cfg[\"classes\"], routings=cfg[\"routings\"], hebb=False)\n",
        "\n",
        "# Run the genetic algorithm\n",
        "ga_instance.run()\n",
        "\n",
        "# Extract the best solution\n",
        "best_solution, best_solution_fitness, _ = ga_instance.best_solution()\n",
        "print(\"Best Fitness Achieved:\", best_solution_fitness)"
      ],
      "metadata": {
        "id": "g_x4nXj2oYDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best solution into the model for testing\n",
        "start = 0\n",
        "for name, param in model.named_parameters():\n",
        "    numel = param.numel()\n",
        "    param.data = torch.tensor(best_solution[start:start + numel]).view(param.shape).to(DEVICE)\n",
        "    start += numel\n",
        "\n",
        "# Test the model with the optimized weights\n",
        "test_loss, test_acc = test(model, test_loader, cfg)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_acc}\")"
      ],
      "metadata": {
        "id": "sX_VBF58obPl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}